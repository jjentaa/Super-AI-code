{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["FuC98AEpAq53","vs6SgOA1AbDD","yDWvEz6qAw35","S74kzm3iBetP","KGO_OrEIxHZ1","VR-MCp8LkcgQ","zl2h1RsrwO5t","ZonLCpJIkoh5"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import zone","metadata":{"id":"NKsHVxmKujdE"}},{"cell_type":"code","source":"from google.colab import drive\n\ndrive.mount('/content/gdrive')","metadata":{"id":"VAgcWgGoKh8c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pytesseract\n!pip install deskew","metadata":{"id":"h_fkbOFgu7hs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport PIL\nfrom PIL import Image\nfrom PIL import ImageDraw\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport time\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport shutil\n\nfrom tqdm import tqdm\nfrom tqdm.notebook import trange, tqdm\nimport pytesseract\nimport re\nimport seaborn as sns\nsns.set_theme()","metadata":{"id":"VGMYdBgGuml3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OCR","metadata":{"id":"MrMz3HljubaP"}},{"cell_type":"markdown","source":"## pytesseract","metadata":{"id":"FuC98AEpAq53"}},{"cell_type":"markdown","source":"### preprocess","metadata":{"id":"vs6SgOA1AbDD"}},{"cell_type":"code","source":"from deskew import determine_skew\n\n\n# Rotate the image around its center\ndef rotateImage(cvImage, angle: float):\n    if(angle > 15):\n        angle = 15.0\n    if(angle < -15):\n        angle = -15.0\n    newImage = cvImage.copy()\n    (h, w) = newImage.shape[:2]\n    center = (w // 2, h // 2)\n    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n    newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n    return newImage\n\n# Deskew image\ndef deskew(cvImage):\n    angle = determine_skew(cvImage)\n    return rotateImage(cvImage, angle)","metadata":{"id":"sejJUjDItBVc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = '/content/Dataset/images/images'\n\nlocal=f'{root}/00182.jpg'\nimg = cv2.imread(local,0)\nfixed = deskew(img)\n\nplt.figure(figsize=(15, 10))\nax1 = plt.subplot(1,2,1)\nimg=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nax1.imshow(img)\nax1.axis('off')\nplt.title(\"Original image\")\n\nax2 = plt.subplot(1,2,2)\nfixed =cv2.cvtColor(fixed , cv2.COLOR_BGR2RGB)\nax2.imshow(fixed)\nax2.axis('off')\nplt.title(\"deskew image\")\n\nplt.show()","metadata":{"id":"XWHsnV9R-_3F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = '/content/Dataset/images/images'\nlocal=f'{root}/00182.jpg'\nimgresize = cv2.imread(local)\n\n#remove noise\ndst = cv2.fastNlMeansDenoisingColored(imgresize, None, 5, 5, 7, 21)\n# Grayscale\ngray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n\ndeskew_ = deskew(gray)\nimgresize2 = deskew_.copy()\ngray_blur = cv2.GaussianBlur(deskew_,(15,15),0)\nthresh=cv2.threshold(gray_blur, 180, 255, cv2.THRESH_BINARY +cv2.THRESH_OTSU)[1]\nkernel=np.ones((5,14),np.uint8)\nclosing = cv2.erode(thresh,kernel,iterations = 2)\nresult_img=closing.copy()\n\ncontours,hierachy=cv2.findContours(result_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\nw,h= result_img.shape\nprint(len(contours))\n\nkernel_sharp = np.array([[0,-1,0],\n                         [-1,5,-1],\n                         [0,-1,0]],dtype=np.float32)\n\nplt.figure(figsize=(20, 2))\n\nfor i, cnt in enumerate(contours):\n    area = cv2.contourArea(cnt)\n\n    if i != len(contours)-1:\n        ax = plt.subplot(2,8,i+1)\n        (x,y,w,h)= cv2.boundingRect(cnt)\n\n        result = imgresize2[y-3:y+h+3,x-2:x+w+5]\n        h_,w_ = result.shape\n        result = cv2.filter2D(result,-1,kernel_sharp)\n        result = cv2.fastNlMeansDenoising(result, None, 20, 7, 21)\n        result = cv2.resize(result, (w_*8,h_*8), interpolation = cv2.INTER_AREA)\n\n        result = cv2.GaussianBlur(result,(11,11),0)\n        result=cv2.threshold(result,180,255,cv2.THRESH_OTSU)[1]\n\n        kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n        kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n\n        result = cv2.erode(result,kernel2,iterations = 1)\n        result =cv2.dilate(result,kernel3,iterations = 10)\n\n        result =cv2.morphologyEx(result,cv2.MORPH_OPEN,kernel2,iterations=5)\n        #result =cv2.morphologyEx(result,cv2.MORPH_CLOSE,kernel2,iterations=4)\n\n        cv2.imwrite('image_cut3/{}.jpg'.format(i),result)\n\n        #forplot\n        result=cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n        ax.imshow(result)\n        ax.axis('off')\n        cv2.rectangle(imgresize2,(x,y),(x+w,y+h),(0,0,255),2)\n\nax.text(-180,-80, 'kernel_sharp image',fontsize=18 )\n\nplt.figure(figsize=(20, 70))\n\ndef plot_step(img,n,text='image') :\n\n    ax1 = plt.subplot(5,2,n)\n    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    ax1.imshow(img)\n    ax1.axis('off')\n    plt.title(text,fontsize=18)\n\nplot_step(imgresize,1,text=\"Original image\")\nplot_step(dst,2,text=\"fastNlMeansDenoisingColored image\")\nplot_step(gray,3,text=\"Gray image\")\nplot_step(deskew_,4,text=\"deskew image\")\nplot_step(gray_blur,5,text=\"GaussianBlur image\")\nplot_step(thresh,6,text=\"THRESH_OTSU image\")\nplot_step(closing,7,text=\"Closing image (Erode)\")\nplot_step(imgresize2,8,text=\"detect text image\")\nplt.subplots_adjust(wspace=0.10, hspace=0.05)\nplt.show()","metadata":{"id":"xuA9QdOm_Mm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n\npath_image_cut= 'image_cut4'\npath_image = '/content/Dataset/images/images'\ntry: shutil.rmtree(path_image_cut)\nexcept : pass\n#Create Folder\nos.mkdir(path_image_cut)\n\n\nkernel_sharp = np.array([[0,-1,0],\n                   [-1,5,-1],\n                   [0,-1,0]],dtype=np.float32)\n\nnum=0\nfor index in tqdm(range(len(os.listdir(path_image)))):\n\n    # print(path_image+'/'+os.listdir(path_image)[index])\n    imgresize = cv2.imread(path_image+'/'+os.listdir(path_image)[index])\n\n    # remove noise\n    dst = cv2.fastNlMeansDenoisingColored(imgresize, None, 5, 5, 7, 21)\n\n    # Grayscale\n    gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n    deskew_ = deskew(gray)\n    imgresize2 = deskew_\n    gray_blur = cv2.GaussianBlur(deskew_,(15,15),0)\n    thresh=cv2.threshold(gray_blur, 180, 255, cv2.THRESH_BINARY +cv2.THRESH_OTSU)[1]\n    kernel=np.ones((5,14),np.uint8)\n    closing = cv2.erode(thresh,kernel,iterations = 2)\n    result_img=closing.copy()\n\n    contours,hierachy=cv2.findContours(result_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n    w,h= result_img.shape\n    print(len(contours),index)\n    num=14*(index+1)-1\n\n    for i, cnt in enumerate(contours):\n        area = cv2.contourArea(cnt)\n\n        if i != len(contours)-1:\n            (x,y,w,h)= cv2.boundingRect(cnt)\n            result = imgresize2[y-3:y+h+3,x-2:x+w+5]\n            h_,w_ = result.shape\n\n            result = cv2.filter2D(result,-1,kernel_sharp)\n            result = cv2.fastNlMeansDenoising(result, None, 20, 7, 21)\n            result = cv2.resize(result, (w_*8,h_*8), interpolation = cv2.INTER_AREA)\n            result = cv2.GaussianBlur(result,(11,11),0)\n            result=cv2.threshold(result,180,255,cv2.THRESH_OTSU)[1]\n            kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n            result =cv2.morphologyEx(result,cv2.MORPH_OPEN,kernel2,iterations=5)\n\n            cv2.imwrite(path_image_cut+'/{}.jpg'.format(num),result)\n            num-=1","metadata":{"id":"yN7SLAvI_QU3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r data.zip /content/image_cut4","metadata":{"id":"Z-MjLidY_UMQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### pytesseract","metadata":{"id":"GPrhihuH_W1y"}},{"cell_type":"code","source":"! sudo apt-get install libpng-dev libjpeg-dev libtiff-dev zlib1g-dev\n! sudo apt-get install gcc g++\n! sudo apt-get install autoconf automake libtool checkinstall","metadata":{"id":"R7ZUxe9q_Upu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! cd ~\n! wget http://www.leptonica.org/source/leptonica-1.73.tar.gz\n! tar -zxvf leptonica-1.73.tar.gz\n! cd leptonica-1.73\n! ./configure\n! make\n! sudo checkinstall\n! sudo ldconfig\n! sudo apt-get install tesseract-ocr","metadata":{"id":"PwlPjITR_cuG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! sudo tesseract --list-langs","metadata":{"id":"wIZlp3v4_eSj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! sudo apt-get install tesseract-ocr-tha\n! sudo tesseract --list-langs","metadata":{"id":"UMsf1xst_gRY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pytesseract\nprint(pytesseract.get_tesseract_version())\nprint(pytesseract.get_languages())","metadata":{"id":"rJ-kNCQA_lDn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_num = [str(x) for x in range(1000)]\ndef clean_data(txt):\n    txt=txt.replace('\\n','')\n    txt=txt.replace('|','')\n\n    if \",\"  in txt:\n        txt=txt[txt.index(',')+1:]\n    elif '.' in txt:\n        txt=txt[txt.index('.')+1:]\n    elif ' ' in txt :\n        txt=txt[txt.index(' ')+1:]\n    elif ':' in txt :\n        txt=txt[txt.index(':')+1:]\n\n    # elif str(j) in txt :\n    #     txt=txt[txt.index(str(j))+1:]\n\n    txt=txt.replace(' ','')\n    txt=txt.replace('-','')\n    txt=txt.replace('๕','&')\n\n    text=re.findall(\"[ก-๙]+\", txt)\n    num=re.findall(\"[0-9]+\", txt)\n    if (len(text) == len(num) != 0)  :\n        txt=text[0]\n    elif len(text) ==0 and len(num) >0 :\n        if str(j) not in txt :\n            txt=num[0]\n        else : txt= '_'\n\n    if txt == '' or txt == None:\n        txt ='_'\n    return txt\n","metadata":{"id":"a4KUaQRw_nOc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test\ndef plot_step2(local,text='image') :\n    img = cv2.imread(local)\n    ax1 = plt.subplot(1,1,1)\n    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    ax1.imshow(img)\n    ax1.axis('off')\n    plt.title(text,fontsize=18)\n    plt.show()","metadata":{"id":"Lq4YIuNy_pG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=0\nn+=1\nfor j in range(1):\n#for j in range(0,14000,1):\n# for j in range(14*n-14,14*n,1):\n# for j in range(len(os.listdir(\"/content/image_cut4/\"))):\n    #local = r'/content/image_cut4/{}.jpg'.format(j)\n    local = '/content/image_process_leawjingjing/0.jpg'\n    img = Image.open(local)\n    txt = pytesseract.image_to_string(local, lang='tha',config='--oem 3 -- psm13') # ocr\n    txt= clean_data(txt,j)\n    plot_step2(local)\n    print(txt)\n    print(\"output :\",txt )\n","metadata":{"id":"1jL7oZay_qnX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = []\npath_image_cut= '/content/image_process_leawjingjing'\nimage_list = os.listdir(path_image_cut)\nprint(len(image_list))\nfor i in tqdm(range(64568)):\n    local = path_image_cut+'/'+str(i)+'.jpg'\n    sub_local = str(i)+'.jpg'\n    if(sub_local in image_list):\n        txt = pytesseract.image_to_string(local, lang='tha',config='--oem 3') # --psm 13 --psm 8\n        txt= clean_data(txt)\n        words.append(txt)\n    else:\n        words.append('_')","metadata":{"id":"CT2wi4eI_2UR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(words)","metadata":{"id":"6n6DAm_N8blx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'Id': list(range(64568)), 'words' : words})\ndf","metadata":{"id":"pUQRGd1bFb5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#edit sth\nfor i in range(len(df)):\n  target = df.loc[i, \"words\"]\n  if(target == \"ถา\"):\n    df.loc[i, \"words\"] = \"กา\"\n  if(target == \"เมือ\")\n  df.loc[i, \"words\"] = \"เมือง\"","metadata":{"id":"dLxMEiNRowNh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"pure-data.csv\", index=False)","metadata":{"id":"L9t6lTL5Fr2p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EASYOCR","metadata":{"id":"yDWvEz6qAw35"}},{"cell_type":"markdown","source":"### preprocess\n\ngray scale + skewer + erosion","metadata":{"id":"04xlq7ORA05T"}},{"cell_type":"code","source":"import sys\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image as im\nfrom scipy.ndimage import interpolation as inter\nfrom scipy.ndimage import rotate","metadata":{"id":"2KbErEpUW0w5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from deskew import determine_skew\n\n\n# Rotate the image around its center\ndef rotateImage(cvImage, angle: float):\n    newImage = cvImage.copy()\n    (h, w) = newImage.shape[:2]\n    center = (w // 2, h // 2)\n    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n    newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n    return newImage\n\n# Deskew image\ndef deskew(cvImage):\n    angle = determine_skew(cvImage)\n    return rotateImage(cvImage, angle)","metadata":{"id":"zAIf0etIBUms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def deskew(imgs):\n#   img = cv2.cvtColor(imgs, cv2.COLOR_BGR2RGB)\n#   img = im.fromarray(img)\n#   # convert to binary\n#   wd, ht = img.size\n#   def find_score(arr, angle):\n#       data = rotate(arr, angle, reshape=False, order=0)\n#       hist = np.sum(data, axis=1)\n#       score = np.sum((hist[1:] - hist[:-1]) ** 2)\n#       return hist, score\n#   delta = 1\n#   limit = 15\n#   angles = np.arange(-limit, limit+delta, delta)\n#   scores = []\n#   for angle in angles:\n#       hist, score = find_score(img, angle)\n#       scores.append(score)\n#   best_score = max(scores)\n#   best_angle = angles[scores.index(best_score)]\n#   #print(f'Best angle: {best_angle}')\n#   # correct skew\n#   data = rotate(img, best_angle, reshape=False, order=0)\n#   img = im.fromarray(data)\n\n#   return img","metadata":{"id":"eVPmBxKKW4Rk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab.patches import cv2_imshow","metadata":{"id":"ZxL37_JrMhIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = '/content/gdrive/MyDrive/SuperAI/hack6/nithan-chadok-hybrid-ocr-ner/images/images'\n\nlocal=root+'/00035.jpg'\nimg = cv2.imread(local)\n#img = np.array(img)\n#print(img.shape)\nfixed = deskew(img)\n\nplt.figure(figsize=(15, 10))\nax1 = plt.subplot(1,2,1)\nimg=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nax1.imshow(img)\nax1.axis('off')\nplt.title(\"Original image\")\n\nax2 = plt.subplot(1,2,2)\n#fixed =cv2.cvtColor(fixed , cv2.COLOR_BGR2RGB)\nax2.imshow(fixed)\nax2.axis('off')\nplt.title(\"deskew image\")\n\nplt.show()","metadata":{"id":"tY8Oks7iLoaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = '/content/gdrive/MyDrive/SuperAI/hack6/nithan-chadok-hybrid-ocr-ner/images/images'\nlocal=root+'/00126.jpg'\nimgresize = cv2.imread(local)\npath_image_cut = 'image_cut_test'\ntry: shutil.rmtree(path_image_cut)\nexcept : pass\nos.mkdir(path_image_cut)\n\n#remove noise\ndst = cv2.fastNlMeansDenoisingColored(imgresize, None, 5, 5, 7, 21)\n# Grayscale\ngray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n\ndeskew_ = deskew(gray)\nimgresize2 = deskew_.copy()\ngray_blur = cv2.GaussianBlur(deskew_,(3,3),0)\nthresh=cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY +cv2.THRESH_OTSU)[1]\nkernel=np.ones((5,14),np.float32)\nclosing = cv2.erode(thresh,kernel,iterations = 2)\nresult_img=closing.copy()\n\ncontours,hierachy=cv2.findContours(result_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\nw,h= result_img.shape\nprint(len(contours))\n\nkernel_sharp = np.array([[0,-1,0],\n                         [-1,5,-1],\n                         [0,-1,0]],dtype=np.float32)\n\nplt.figure(figsize=(20, 2))\ncounter = 0\n\nfor i, cnt in enumerate(contours):\n    area = cv2.contourArea(cnt)\n\n    if i != len(contours)-1:\n        ax = plt.subplot(2,8,i+1)\n        (x,y,w,h)= cv2.boundingRect(cnt)\n\n        result = imgresize2[y-3:y+h+3,x-2:x+w+5]\n        h_,w_ = result.shape\n        result = cv2.filter2D(result,-1,kernel_sharp)\n        result = cv2.fastNlMeansDenoising(result, None, 20, 7, 21)\n        result = cv2.resize(result, (w_*8,h_*8), interpolation = cv2.INTER_AREA)\n\n        result = cv2.GaussianBlur(result,(11,11),0)\n        result=cv2.threshold(result,0,255,cv2.THRESH_OTSU)[1]\n\n        kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n        kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n\n        result = cv2.erode(result,kernel2,iterations = 1)\n        result =cv2.dilate(result,kernel3,iterations = 10)\n\n        result =cv2.morphologyEx(result,cv2.MORPH_OPEN,kernel2,iterations=5)\n        #result =cv2.morphologyEx(result,cv2.MORPH_CLOSE,kernel2,iterations=4)\n\n        cv2.imwrite(f'{path_image_cut}/{counter}.jpg',result)\n\n        #forplot\n        result=cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n        ax.imshow(result)\n        ax.axis('off')\n        cv2.rectangle(imgresize2,(x,y),(x+w,y+h),(0,0,255),2)\n    counter+=1\n\nax.text(-180,-80, 'kernel_sharp image',fontsize=18 )\n\nplt.figure(figsize=(20, 70))\n\ndef plot_step(img,n,text='image') :\n\n    ax1 = plt.subplot(5,2,n)\n    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    ax1.imshow(img)\n    ax1.axis('off')\n    plt.title(text,fontsize=18)\n\nplot_step(imgresize,1,text=\"Original image\")\nplot_step(dst,2,text=\"fastNlMeansDenoisingColored image\")\nplot_step(gray,3,text=\"Gray image\")\nplot_step(deskew_,4,text=\"deskew image\")\nplot_step(gray_blur,5,text=\"GaussianBlur image\")\nplot_step(thresh,6,text=\"THRESH_OTSU image\")\nplot_step(closing,7,text=\"Closing image (Erode)\")\nplot_step(imgresize2,8,text=\"detect text image\")\nplt.subplots_adjust(wspace=0.10, hspace=0.05)\nplt.show()","metadata":{"id":"_M0Y7SBTNkCg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = '/content/gdrive/MyDrive/SuperAI/hack6/nithan-chadok-hybrid-ocr-ner/images/images'\npath_image_cut = 'image_process_leawjingjing'\ntry: shutil.rmtree(path_image_cut)\nexcept : pass\nos.mkdir(path_image_cut)\n\nall_path = os.listdir(root)\nall_path.sort()\n#all_path","metadata":{"id":"T-JYTaOIovOn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = 0\nfor index in tqdm(range(len(all_path))):\n    #print(all_path[index])\n    imgresize = cv2.imread(root+'/'+all_path[index])\n    #remove noise\n    dst = cv2.fastNlMeansDenoisingColored(imgresize, None, 5, 5, 7, 21)\n    # Grayscale\n    gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n\n    deskew_ = deskew(gray)\n    imgresize2 = deskew_.copy()\n    gray_blur = cv2.GaussianBlur(deskew_,(3,3),0)\n    thresh=cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY +cv2.THRESH_OTSU)[1]\n    kernel=np.ones((5,14),np.float32)\n    closing = cv2.erode(thresh,kernel,iterations = 2)\n    result_img=closing.copy()\n\n    contours,hierachy=cv2.findContours(result_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n    w,h= result_img.shape\n    print(index, len(contours))\n\n    kernel_sharp = np.array([[0,-1,0],\n                            [-1,5,-1],\n                            [0,-1,0]],dtype=np.float32)\n\n    plt.figure(figsize=(20, 2))\n    counter = 0\n    num=14*(index+1)-1\n\n    for i, cnt in enumerate(contours):\n        area = cv2.contourArea(cnt)\n\n        if i != len(contours)-1:\n            (x,y,w,h)= cv2.boundingRect(cnt)\n\n            result = imgresize2[y-3:y+h+3,x-2:x+w+5]\n            h_,w_ = result.shape\n            if(not result.size==0):\n                result = cv2.filter2D(result,-1,kernel_sharp)\n                result = cv2.fastNlMeansDenoising(result, None, 20, 7, 21)\n                result = cv2.resize(result, (w_*8,h_*8), interpolation = cv2.INTER_AREA)\n\n                result = cv2.GaussianBlur(result,(11,11),0)\n                result=cv2.threshold(result,0,255,cv2.THRESH_OTSU)[1]\n\n                kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n                kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n\n                result = cv2.erode(result,kernel2,iterations = 1)\n                result =cv2.dilate(result,kernel3,iterations = 10)\n\n                result =cv2.morphologyEx(result,cv2.MORPH_OPEN,kernel2,iterations=5)\n                #result =cv2.morphologyEx(result,cv2.MORPH_CLOSE,kernel2,iterations=4)\n\n                cv2.imwrite(f'{path_image_cut}/{num}.jpg',result)\n\n        counter+=1\n        num-=1","metadata":{"id":"lcN3DNZrmw6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r data.zip /content/image_process_leawjingjing","metadata":{"id":"KDGJt4LxzOrz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /content/image_process_leawjingjing /content/gdrive/MyDrive/SuperAI/hack6/data_processed","metadata":{"id":"b7mWT3bRzZbW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%rm -rf image_process_leawja","metadata":{"id":"XccI4G5wgcB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%rm -rf image_cut\n%rm -rf image_cut+erode\n%rm -rf image_cut+test\n%rm -rf image_cut3\n%rm -rf image_cut_test\n%rm -rf image_pro\n%rm -rf image_process\n%rm -rf image_process_cut","metadata":{"id":"wMIMo6y4fD7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from glob import glob\n\n# path_image_cut= 'image_process_leawja'\n# path_image = '/content/gdrive/MyDrive/SuperAI/hack6/nithan-chadok-hybrid-ocr-ner/images/images'\n# try: shutil.rmtree(path_image_cut)\n# except : pass\n# #Create Folder\n# os.mkdir(path_image_cut)\n\n\n# kernel_sharp = np.array([[0,-1,0],\n#                    [-1,5,-1],\n#                    [0,-1,0]],dtype=np.float32)\n\n# num=0\n# counter = 0\n# for index in tqdm(range(len(os.listdir(path_image)))):\n\n#     # print(path_image+'/'+os.listdir(path_image)[index])\n#     imgresize = cv2.imread(path_image+'/'+os.listdir(path_image)[index])\n\n#     # remove noise\n#     dst = cv2.fastNlMeansDenoisingColored(imgresize, None, 5, 5, 7, 21)\n\n#     # Grayscale\n#     gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n\n#     deskew_ = deskew(gray)\n#     imgresize2 = deskew_.copy()\n#     gray_blur = cv2.GaussianBlur(deskew_,(5, 5),0)\n#     thresh=cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY +cv2.THRESH_OTSU)[1]\n#     #kernel=np.ones((5,14),np.uint8)\n#     kernel1 = np.ones((5, 14), np.float32)\n#     closing = cv2.erode(thresh,kernel,iterations = 2)\n#     result_img=closing.copy()\n\n#     contours,hierachy=cv2.findContours(result_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n#     w,h= result_img.shape\n#     print(len(contours),index)\n#     num=14*(index+1)-1\n#     #counter+=14\n\n#     for i, cnt in enumerate(contours):\n#         area = cv2.contourArea(cnt)\n\n#         if i != len(contours)-1:\n#             (x,y,w,h)= cv2.boundingRect(cnt)\n#             result = imgresize2[y-3:y+h+3,x-2:x+w+5]\n#             h_,w_ = result.shape\n#             #print(len(contours))\n\n#             if(not result.size == 0):\n#                 result = cv2.filter2D(result,-1,kernel_sharp)\n#                 result = cv2.fastNlMeansDenoising(result, None, 20, 7, 21)\n#                 result = cv2.resize(result, (w_*8,h_*8), interpolation = cv2.INTER_AREA)\n#                 result = cv2.GaussianBlur(result,(11,11),0)\n#                 result=cv2.threshold(result, 0,255,cv2.THRESH_OTSU)[1]\n#                 kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n#                 kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n\n#                 result = cv2.erode(result, kernel2, iterations=1)\n#                 result = cv2.dilate(result, kernel3, iterations=10)\n#                 result =cv2.morphologyEx(result,cv2.MORPH_OPEN,kernel2,iterations=5)\n\n#             #erode\n#             #image = cv2.erode(result, kernel1)\n\n#                 cv2.imwrite(path_image_cut+f'/{num-1}.jpg'.format(num),result)\n#             num-=1\n#             print(num)\n#         #counter+=1","metadata":{"id":"R9eafIx4P1qB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r data.zip /content/image_cut4","metadata":{"id":"nVqXIlXTN5CO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### easyocr model","metadata":{"id":"S74kzm3iBetP"}},{"cell_type":"code","source":"! pip install -q easyocr","metadata":{"id":"5OdSFDU7BhJw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls = os.listdir(\"/content/image_process_leawjingjing\")\nlen(ls)","metadata":{"id":"UvA1ewsf4NIc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import easyocr\nimport pandas as pd\npath = \"/content/image_process_leawjingjing\"\nreader = easyocr.Reader(['th'])\n\nwords = []\n\n# plt.figure(figsize=(20, 70))\n\n# def plot_step(img,n,text='image') :\n\n#     ax1 = plt.subplot(7,2,n)\n#     img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#     ax1.imshow(img)\n#     ax1.axis('off')\n#     plt.title(text,fontsize=18)\n\nfor index in tqdm(range(1)):\n#for index in tqdm(range(len(os.listdir(path)))):\n  #img = cv2.imread(path+'/'+os.listdir(path)[index])\n  #print(path+'/'+os.listdir(path)[index])\n  result = reader.readtext(path+'/'+'0.jpg')\n  #plot_step(img, index+1)\n  print(result)","metadata":{"id":"zYDyUS6HBh0-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NLP","metadata":{"id":"ddEmjEpLUdBI"}},{"cell_type":"code","source":"from google.colab import drive\n\ndrive.mount('/content/gdrive')","metadata":{"id":"HjmUvcgaxxp0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## test Spelling function","metadata":{"id":"KGO_OrEIxHZ1"}},{"cell_type":"code","source":"!pip install pythainlp","metadata":{"id":"IKb5gEQDUe6N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install fasttext","metadata":{"id":"joujRJUxk6CB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test function\nfrom pythainlp import spell\n\ntarget = \"มีคุณคา\"\npred = spell(target)\n\nprint(pred[0])\nprint(pred)","metadata":{"id":"HA-f1oKwUl5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pythainlp.spell import correct_sent\n\ncorrect_sent([\"มีคุณคา\",\"งขานจักดาน\",\"จึ่ง\"])","metadata":{"id":"TAxQTrsL_5HN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pythainlp.spell import NorvigSpellChecker\n\nchecker = NorvigSpellChecker()\n\nchecker.correct(\"มีคุณคา\")","metadata":{"id":"rtHtz-PcAQ19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test function\nfrom pythainlp.spell import correct\n\ntarget = \"มีคุณคา\"\npred = correct(target)\n#pred = correct(target, engine=\"wanchanberta_thai_grammarly\")\n\nprint(pred)","metadata":{"id":"NfGjEK3K04x0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## spelling tune model","metadata":{"id":"VR-MCp8LkcgQ"}},{"cell_type":"code","source":"import pythainlp\nimport numpy as np\n\nwords = pythainlp.corpus.ttc.word_freqs()\n#words = np.array(list(words))  # to array","metadata":{"id":"rp3Qp92PkfBo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words\nall_words = []\nfor i in words:\n  all_words.append(i[0])","metadata":{"id":"3rMH8Np2sgYq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_words = np.array(all_words)\nall_words.shape","metadata":{"id":"v10H45mbsqG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = thai_words()\ndf","metadata":{"id":"05OsP24ooPdk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1709876330236,"user":{"displayName":"madness","userId":"05668767824439413557"},"user_tz":-420},"id":"0U_8iRM0kgx4","outputId":"4bd05245-cb81-42c4-af6a-6b476b8509b1"},"execution_count":null,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":["(62074,)"]},"metadata":{}}]},{"cell_type":"code","source":"words_str = '\\n'.join(all_words)\nwords_char = list(words_str)","metadata":{"id":"iCDUqzo1knor"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('words-char.txt', mode='w', encoding='utf-8') as file:\n    file.write(' '.join(words_char))","metadata":{"id":"hv8cnPQ5ksMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import fasttext","metadata":{"id":"kFo329RrlYp5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = fasttext.train_unsupervised('words-char.txt',\n                                    epoch=200,\n                                    ws=3)","metadata":{"id":"MOTeMy9tktRY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_vec = [model.get_sentence_vector(' '.join(list(word))) for word in all_words]\nwords_vec = np.array(words_vec)","metadata":{"id":"UCsMPzlJkvQM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\nimport numpy as np\n\nX, y = words_vec, words\nnbrs = NearestNeighbors().fit(X, y)","metadata":{"id":"HFpTVZy-lmLC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\n\nmodel.save_model('char2vec.bin')  # fasttext model\njoblib.dump(words, 'words.joblib')\njoblib.dump(nbrs, 'nbrs.joblib');","metadata":{"id":"kVjpBCPLlqW9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import fasttext\nimport joblib\n\nmodel = fasttext.load_model('char2vec.bin')\nwords = joblib.load('words.joblib')\nnbrs = joblib.load('nbrs.joblib')","metadata":{"id":"rXvIfJl-ltAA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_input = ['มีคุณคา', 'งขานจักดาน', 'หัตอกางน', 'ศิดปหัดดกรรม', 'ธรรมยาติ']","metadata":{"id":"bhCzS8k3lx4d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_input_vec = [model.get_sentence_vector(' '.join(list(word))) for word in words_input]\nindices = nbrs.kneighbors(word_input_vec, 5, False)  # n_neighbors is 5\nsuggestion = all_words[indices]\n\nfor w, s in zip(words_input, suggestion):\n    print(f'{w} \\n---> {s}')","metadata":{"id":"RJHiUppql8_p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## word beam search","metadata":{"id":"zl2h1RsrwO5t"}},{"cell_type":"code","source":"! git clone https://github.com/githubharald/SimpleHTR","metadata":{"id":"Y5MD3rkbwXHO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! git clone https://github.com/githubharald/CTCWordBeamSearch","metadata":{"id":"lSfcQgEbwZGn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install CTCWordBeamSearch\n%cd CTCWordBeamSearch\n! pip install .","metadata":{"id":"_WNH_q-owRTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom word_beam_search import WordBeamSearch\n\ncorpus = 'คามณี คุณงาม กามคุณ สมนาคุณ คุณค่า'  # two words \"a\" and \"ba\", separated by whitespace\nchars = 'คุณคา '  # the characters that can be recognized (in this order)\nword_chars = 'คุณา'  # characters that form words\n\n# RNN output\n# 3 time-steps and 4 characters per time time (\"a\", \"b\", \" \", CTC-blank)\nmat = np.array([\n    [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]],\n    [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]],\n    [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]],\n    [[0.4, 0.6, 0.0, 0.0, 0.0, 0.0]]\n])\n\n# initialize word beam search (only do this once in your code)\nwbs = WordBeamSearch(\n    25,\n    'Words', # \"NGrams\", \"NGramsForecast\", \"NGramsForecastAndSample\"\n    0.0,\n    corpus.encode('utf8'),\n    chars.encode('utf8'),\n    word_chars.encode('utf8')\n)\n\n# compute label string\nlabel_str = wbs.compute(mat)\n\nchar_str = [''.join(chars[label] for label in curr_label_str) for curr_label_str in label_str]\n\n\nchar_str","metadata":{"id":"0VRiLmmUwSJC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## spelling checker","metadata":{"id":"ZonLCpJIkoh5"}},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(\"/content/gdrive/MyDrive/SuperAI/hack6/csv-keeper/df_test_new-BW_1.csv\")","metadata":{"id":"5OQyomMhyd7R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"LbEfvL9jzBV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(data)):\n  word = data.loc[i, \"Text\"]\n  pred = correct(word)\n\n  if(i%100==0):\n    print(i)\n\n  data.loc[i, \"CS text\"] = pred[0] #CS text = correct spelling text","metadata":{"id":"c5cAJD9ey8tk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"lGV2c5FezWgZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv(\"/content/gdrive/MyDrive/SuperAI/hack6/csv-keeper/spelling_test_1.csv\", index=False)","metadata":{"id":"u-a6e81A0KrE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NER","metadata":{"id":"HuZkigd75JYY"}},{"cell_type":"code","source":"!pip install -q simpletransformers","metadata":{"id":"Tm4pTXqC5vrI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom simpletransformers.ner import NERModel, NERArgs","metadata":{"id":"5aIF95sU51Y-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/content/cheat4.csv\")","metadata":{"id":"z1upTS-C5jRo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts_test_raw = []\nfor i in range(len(test_df)):\n  texts_test_raw.append(test_df.loc[i, \"words\"])","metadata":{"id":"f6NPQjAX5rQi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def blank_space(x):\n  if x == '' or x == None or str(x)=='nan':\n    x = '_'\n  return x\n\n#Loop replace blank to \"_\"\nfor i in range(len(texts_test_raw)):\n  texts_test_raw[i] = blank_space(texts_test_raw[i])","metadata":{"id":"OxO5DGq8568s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_into_sentences(tokens, tokens_per_sentence=40):\n    sentences = []\n    for i in range(0, len(tokens), tokens_per_sentence):\n        sentence = tokens[i:i+tokens_per_sentence]\n        sentences.append(sentence)\n    return sentences","metadata":{"id":"Ee4rLLh5586P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_token = split_into_sentences(texts_test_raw)","metadata":{"id":"rs6lw5HO5_8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sent_join = ' '.join(my_token[0])\ntype(sent_join)","metadata":{"id":"S1gVP2iI6Bgf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_token_list = []\nfor i in range(len(my_token)):\n  sent_join = ' '.join(my_token[i])\n  #print(sent_join)\n  my_token_list.append(sent_join)","metadata":{"id":"t19BOhRe6EI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_NER_TAGS = [\n        \"O\",\n        \"B_BRN\",\n        \"B_DES\",\n        \"B_DTM\",\n        \"B_LOC\",\n        \"B_MEA\",\n        \"B_NUM\",\n        \"B_ORG\",\n        \"B_PER\",\n        \"B_TRM\",\n        \"B_TTL\",\n        \"I_BRN\",\n        \"I_DES\",\n        \"I_DTM\",\n        \"I_LOC\",\n        \"I_MEA\",\n        \"I_NUM\",\n        \"I_ORG\",\n        \"I_PER\",\n        \"I_TRM\",\n        \"I_TTL\",\n        \"E_BRN\",\n        \"E_DES\",\n        \"E_DTM\",\n        \"E_LOC\",\n        \"E_MEA\",\n        \"E_NUM\",\n        \"E_ORG\",\n        \"E_PER\",\n        \"E_TRM\",\n        \"E_TTL\",\n    ]","metadata":{"id":"UJzolERO6N5K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Model\nner_args = NERArgs()\nner_args.eval_batch_size = 128\nner_args.use_multiprocessing = True\nmodel = NERModel(\n     \"camembert\", \"/content/gdrive/MyDrive/SuperAI/model/best_model_wangchanberta_addarg\", args=ner_args, use_cuda=torch.cuda.is_available(), labels=_NER_TAGS  # your latest model\n)","metadata":{"id":"sC4ZA__c6GZS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, raw_outputs = model.predict(my_token, False)","metadata":{"id":"bbX4ojcU6IMn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extract data value from dict list\nfinal_test_df = []\nfor i in range(len(predictions)):\n  for j in range(len(predictions[i])):\n    data = predictions[i][j]\n    #print(data, type(data))\n    value = data.values()\n    final_test_df += value","metadata":{"id":"ZxXIoKyK9PTf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final_test_df)","metadata":{"id":"YPMpZaOnGQFH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"tag2idx","metadata":{"id":"yQRjt6GY6PPZ"}},{"cell_type":"code","source":"tag_list = pd.read_csv(\"/content/gdrive/MyDrive/SuperAI/tag_list.csv\")","metadata":{"id":"4S3YPp8n6Oz0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tag_list","metadata":{"id":"uAiGxeKpHGOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tag2class = {}\nfor i in range(len(tag_list)):\n  tag2class[tag_list.loc[i, \"tag\"]] = tag_list.loc[i, \"class\"]","metadata":{"id":"qwWMYGku6W_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tag2class","metadata":{"id":"FNzURERaIQ0M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_result = pd.DataFrame(final_test_df, columns=[\"pred\"])\nfinal_result","metadata":{"id":"a0zybZ2I9bt7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(final_result)):\n  final_result.loc[i,\"pred2id\"] = str(tag2class[final_result.loc[i, \"pred\"]])","metadata":{"id":"4kGl7Uzl9dxs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking unique tag\n\nx = final_result[\"pred\"].unique()\nprint(len(x))\nprint(x)","metadata":{"id":"oUwccnUc9feD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709972932179,"user_tz":-420,"elapsed":15,"user":{"displayName":"Jenta Wonglertsakul","userId":"02389428147928105100"}},"outputId":"f964d671-6c69-466c-e3dc-3cac2d35425f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"19\n\n['O' 'B_LOC' 'E_LOC' 'B_PER' 'B_TTL' 'E_PER' 'B_NUM' 'E_ORG' 'B_MEA'\n\n 'B_DTM' 'I_PER' 'B_ORG' 'E_MEA' 'I_LOC' 'I_MEA' 'I_ORG' 'B_DES' 'E_DTM'\n\n 'I_DTM']\n"}]},{"cell_type":"code","source":"for i in range(len(test_df)):\n    target = test_df.loc[i, \"words\"]\n\n    #animal\n    ani = \"ราชสีห์,เสือ,เสือโคร่ง,ลา,แร้ง,หงส์,เสือดาว,หงส์,กา,นกหัวขวาน,จระเข้,นกยูง,สุนัข,สุนัขจิ้งจอก,หมี,แพะ,พญาลิง,ลิง,พญาหงส์ทอง,หงส์ทอง,แร้ง,ช้าง\"\n    ani_ls = ani.split(',')\n    if(target in ani_ls):\n        final_result.loc[i, \"pred\"] = \"0\"\n    #นายพราน\n    if(\"นายพราน\" in target):\n        final_result.loc[i, \"pred\"] = \"0\"\n    #prefix\n    if(target in [\"ท้าว\", \"พญา\", \"ท่าน\", \"พระ\"]):\n        final_result.loc[i, \"pred\"] = \"9\"\n    #prefix sth\n    if(target in [\"ท้าว\", \"เจ้า\"]):\n        final_result.loc[i, \"pred\"] = \"11\"\n    #มีแต่่ 12\n    if(final_result.loc[i, \"pred\"] == \"12\"):\n        final_result.loc[i-1, \"pred\"] = \"3\"\n    #\"_\" + สรรพนามแทนตัวเอง\n    if(target in [\"_\", \"เรา\", \"ข้าพเจ้า\"]):\n        final_result.loc[i, \"pred\"] = \"0\"\n    # ที่ + order number\n    if (target == \"ที่\") and str(test_df.loc[i+2, \"word\"]).isdigit() :\n        final_result.loc[i, \"pred\"] = \"4\"\n    # pair of 4 and 17\n    if(final_result.loc[i, \"pred\"]==\"4\") and (final_result.loc[i+2, \"pred\"]==\"17\"):\n        final_result.loc[i+1, \"pred\"] = \"15\"\n    # place\n    if(target in [\"วัด\", \"เมือง\", \"ป่า\"]):\n        final_result.loc[i, \"pred\"] = \"3\"\n        final_result.loc[i+1, \"pred\"] = \"12\"","metadata":{"id":"aGxitxymFUr3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/content/gdrive/MyDrive/SuperAI/sample_submission.csv\")","metadata":{"id":"KPppD4Aw9kWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"pred\"] = final_result[\"pred2id\"]","metadata":{"id":"koo1r7q19qnG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"id":"Zzme835E9xDB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"prediction-3k.csv\", index=False)","metadata":{"id":"ZU_SltZuI7lw"},"execution_count":null,"outputs":[]}]}